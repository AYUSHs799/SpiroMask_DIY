{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import lfilter\n",
    "from scipy.signal import butter\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import speechpy\n",
    "import tsfel\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Bandpass Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Butterworth Bandpass Filter\n",
    "def butter_bandpass(lowcut : int, highcut : int, fs : int, order=5):\n",
    "    \"\"\" Create a Butterworth Bandpass Filter\n",
    "\n",
    "        \\tlowcut: low cut frequency (in Hz)\n",
    "        \\thighcut: high cut frequency (in Hz)\n",
    "        \\tfs: sampling frequency (in Hz)\n",
    "        \\torder: order of the filter (default = 5)\n",
    "\n",
    "        return: b, a: numerator (b) and denominator (a) polynomials of the IIR filter   \"\"\"\n",
    "\n",
    "    nyq = 0.5 * fs                                      # Nyquist frequency (half of the sampling frequency)\n",
    "    low = lowcut / nyq                                  # Normalized low cut frequency\n",
    "    high = highcut / nyq                                # Normalized high cut frequency\n",
    "    b, a = butter(order, [low, high], btype='band')     # Create Butterworth bandpass filter\n",
    "    return b, a                                         # Return numerator (b) and denominator (a) polynomials of the IIR filter\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut : int, highcut : int, fs : int, order=5):\n",
    "    \"\"\"     Apply a Butterworth Bandpass Filter   \n",
    "            \n",
    "            \\tdata: signal to be filtered\n",
    "            \\tlowcut: low cut frequency (in Hz)\n",
    "            \\thighcut: high cut frequency (in Hz)\n",
    "            \\tfs: sampling frequency (in Hz)\n",
    "            \\torder: order of the filter (default = 5)\n",
    "\n",
    "            return: y: filtered signal   \"\"\"\n",
    "\n",
    "\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)    # Create Butterworth bandpass filter\n",
    "    y = lfilter(b, a, data)                                     # Apply filter\n",
    "    return y                                                    # Return filtered signal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Finding Peak Landmarks (Start, End, and Peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_start_peak_end(x_filt,windowsize=100):\n",
    "    \"\"\"     Find the start, peak and end of the signal\n",
    "            \\tx_filt: filtered signal\n",
    "            \\twindowsize: size of the window to calculate the standard deviation (default = 100)\n",
    "            return: start, peak, end: start, peak and end of the signal   \"\"\"\n",
    "\n",
    "    peak = np.argmax(np.abs(x_filt))    # Find the peak of the signal\n",
    "    start=0                             # Initialize start \n",
    "    end = len(x_filt)                   # Initialize end\n",
    "\n",
    "    std_cutoff = np.std(x_filt)/10      # Set the standard deviation cutoff\n",
    "\n",
    "    # Find the start and end of the signal\n",
    "    for i in range(peak,0,-windowsize):  \n",
    "\n",
    "        # Calculate the standard deviation of the signal in the window\n",
    "        std = np.std(x_filt[i:i+windowsize])\n",
    "\n",
    "        # If the standard deviation is less than the cutoff, set the start of the signal\n",
    "        if std <= std_cutoff:\n",
    "            start = i\n",
    "            break\n",
    "\n",
    "    # Find the end of the signal\n",
    "    for j in range(peak,len(x_filt),windowsize):\n",
    "\n",
    "        # Calculate the standard deviation of the signal in the window\n",
    "        std = np.std(x_filt[j:j+windowsize])\n",
    "\n",
    "        # If the standard deviation is less than the cutoff, set the end of the signal\n",
    "        if std <= std_cutoff:\n",
    "            end = j\n",
    "            break\n",
    "    \n",
    "    # Sanity check so that end doesn't go out of bounds\n",
    "    if end==len(x_filt):\n",
    "        end = len(x_filt)-3201\n",
    "    \n",
    "    # Adding 0.1s of margin to end \n",
    "    return start,peak,end+3200"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Audio_Feature_Extractor(directory='./N95/',build_header=True,build_spectrogram=True,build_mfc=True,build_melspectogram=True,build_mfe=True,build_mfcc=True,build_spectral_features=True,build_temporal_features=True,Apply_Bandpass_Filter=False,cutoff_low=1250,cutoff_high=2500,order=5,Apply_clipping=False,Auto_Clipping=False,clip_start=12800,clip_end=48000, Normalize=False):\n",
    "\n",
    "    \"\"\" \n",
    "    This function extracts the features from the audio files in the given directory.\\n\n",
    "    The features extracted are:\\n\n",
    "        1. Spectrogram (STFT) (uses librosa library for extraction)\n",
    "        2. MFC (uses librosa library for extraction)\n",
    "        3. Mel Spectrogram  (uses librosa library for extraction)\n",
    "        4. MFE  (uses speechpy library for extraction)\n",
    "        5. MFCC  (uses speechpy library for extraction)\n",
    "        6. MFCC CMVN  (uses speechpy library for extraction)\n",
    "        7. Spectral Features  (uses tsfel library for extraction)\n",
    "        8. Temporal Features  (uses tsfel library for extraction)\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): Path to the directory containing the audio files.\n",
    "        build_header (bool): If True, the header is built.\n",
    "        build_spectrogram (bool): If True, the spectrogram is built.\n",
    "        build_mfc (bool): If True, the MFC is built.\n",
    "        build_melspectogram (bool): If True, the mel spectrogram is built.\n",
    "        build_mfe (bool): If True, the MFE is built.\n",
    "        build_mfcc (bool): If True, the MFCC is built.\n",
    "        build_spectral_features (bool): If True, the spectral features are built.\n",
    "        build_temporal_features (bool): If True, the temporal features are built.\n",
    "        Apply_Bandpass_Filter (bool): If True, the bandpass filter is applied.\n",
    "        cutoff_low (int): Lower cutoff frequency for the bandpass filter.\n",
    "        cutoff_high (int): Higher cutoff frequency for the bandpass filter.\n",
    "        order (int): Order of the bandpass filter.\n",
    "        Apply_clipping (bool): If True, the audio is clipped.\n",
    "        clip_start (int): Starting point of the audio clip.\n",
    "        clip_end (int): Ending point of the audio clip.\n",
    "        Normalize (bool): If True, the wave is normalised before extracting features.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    all_features = []\n",
    "    header = ['pid']\n",
    "    i=0\n",
    "    \n",
    "    # Toggle through all the files in the directory.\n",
    "    for filename in os.listdir(directory):\n",
    "\n",
    "        # Path to the file.\n",
    "        f = os.path.join(directory, filename)\n",
    "\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(f):\n",
    "            \n",
    "            i=i+1\n",
    "            print(i,'/',len(os.listdir(directory)))\n",
    "\n",
    "            curr_feature = np.array([])\n",
    "\n",
    "            # Loading the audio file\n",
    "            x , sr = librosa.load(f,sr=16000)\n",
    "\n",
    "\n",
    "            if Normalize:\n",
    "                x = x/np.max(np.abs(x))\n",
    "\n",
    "            # Applying bandpass filter\n",
    "            if Apply_Bandpass_Filter:\n",
    "                x = butter_bandpass_filter(x,cutoff_low,cutoff_high,sr,order)\n",
    "\n",
    "            # Normalizing the wave\n",
    "            if Normalize:\n",
    "                x = x/np.max(np.abs(x))\n",
    "\n",
    "            # Applying clipping\n",
    "            if Apply_clipping:\n",
    "                if Auto_Clipping:\n",
    "                    start,peak,end = find_start_peak_end(x)\n",
    "                    x = x[start:end]\n",
    "                else:\n",
    "                    x = x[clip_start:clip_end]\n",
    "\n",
    "            # Retrieving the patient ID from the filename.\n",
    "            pid = np.array([filename.split('.')[0]])\n",
    "            curr_feature = np.concatenate((curr_feature,pid))\n",
    "\n",
    "            # Extracting the features.\n",
    "            num_filters     =   40\n",
    "            num_cepstral    =   5 \n",
    "            fft_length      =   512\n",
    "\n",
    "            # Spectrogram of the audio file.\n",
    "            if build_spectrogram:\n",
    "                stft_spectrogram=np.mean(np.abs(librosa.stft(x, n_fft=480, hop_length=240)),axis=1)\n",
    "                curr_feature = np.concatenate((curr_feature,stft_spectrogram))\n",
    "                if build_header:\n",
    "                    header.extend(['stft_spectrogram_'+str(i) for i in range(stft_spectrogram.shape[0])])\n",
    "\n",
    "            # MFC coeff of the audio file.\n",
    "            if build_mfc:\n",
    "                mfc_coefficients = np.mean(librosa.feature.mfcc(y=x, n_mfcc=50, sr=16000),axis=1)\n",
    "                curr_feature = np.concatenate((curr_feature,mfc_coefficients))\n",
    "                if build_header:\n",
    "                    header.extend(['mfc_coefficients_'+str(i) for i in range(mfc_coefficients.shape[0])])\n",
    "\n",
    "            # Mel Spectrogram of the audio file.\n",
    "            if build_melspectogram:\n",
    "                melspectogram = np.mean(librosa.feature.melspectrogram(y=x, sr=16000, n_mels=16, n_fft=480, hop_length=240),axis=1)\n",
    "                curr_feature = np.concatenate((curr_feature,melspectogram))\n",
    "                if build_header:\n",
    "                    header.extend(['melspectogram_'+str(i) for i in range(melspectogram.shape[0])])\n",
    "\n",
    "            # MFE of the audio file.\n",
    "            if build_mfe:\n",
    "                mfe = np.mean(speechpy.feature.mfe(x, sampling_frequency=16000, frame_length=0.030, frame_stride=0.015,num_filters=num_filters,fft_length=fft_length,low_frequency=0)[0],axis=0)\n",
    "                curr_feature = np.concatenate((curr_feature,mfe))\n",
    "                if build_header:\n",
    "                    header.extend(['mfe_'+str(i) for i in range(mfe.shape[0])])\n",
    "\n",
    "            # MFCC and MFCC CMVN of the audio file.\n",
    "            if build_mfcc:\n",
    "                mfcc = speechpy.feature.mfcc(x, sampling_frequency=16000, frame_length=0.030, frame_stride=0.015,num_filters=num_filters, fft_length=fft_length, low_frequency=0, num_cepstral=num_cepstral)\n",
    "        \n",
    "                mfcc_cmvn = np.mean(speechpy.processing.cmvnw(mfcc,win_size=301,variance_normalization=True), axis=0)\n",
    "                mfcc = np.mean(mfcc,axis=0)\n",
    "                curr_feature = np.concatenate((curr_feature,mfcc))\n",
    "                curr_feature = np.concatenate((curr_feature,mfcc_cmvn))\n",
    "                if build_header:\n",
    "                    header.extend(['mfcc_'+str(i) for i in range(mfcc.shape[0])])\n",
    "                    header.extend(['mfcc_cmvn_'+str(i) for i in range(mfcc_cmvn.shape[0])])\n",
    "\n",
    "            # Spectral features of the audio file.\n",
    "            if build_spectral_features:\n",
    "                cfg = tsfel.get_features_by_domain(\"spectral\")\n",
    "                spectral_features = np.array(tsfel.time_series_features_extractor(cfg, x, fs=16000, window=320,verbose=0))[0]\n",
    "                curr_feature = np.concatenate((curr_feature,spectral_features))\n",
    "                if build_header:\n",
    "                    header.extend(['spectral_features_'+str(i) for i in range(spectral_features.shape[0])])\n",
    "\n",
    "            # Temporal features of the audio file.\n",
    "            if build_temporal_features:\n",
    "                cfg = tsfel.get_features_by_domain('temporal') \n",
    "                temporal_features = np.array(tsfel.time_series_features_extractor(cfg, x, fs=16000, window=300,verbose=0))[0]\n",
    "                curr_feature = np.concatenate((curr_feature,temporal_features))\n",
    "                if build_header:\n",
    "                    header.extend(['temporal_features_'+str(i) for i in range(temporal_features.shape[0])])\n",
    "\n",
    "            # Combining all the features.\n",
    "            # curr_feature = np.concatenate((pid,stft_spectrogram,mfc_coefficients,melspectogram,mfe,mfcc,mfcc_cmvn,spectral_features,temporal_features))\n",
    "            print('Feature extracted for',pid[0],' : ',curr_feature.shape[0])\n",
    "            \n",
    "            if build_header:\n",
    "                all_features.append(header)\n",
    "                build_header = False\n",
    "                print('Header Added')\n",
    "\n",
    "            all_features.append(curr_feature)\n",
    "\n",
    "    print(\"\\nFeature Extraction Done\")\n",
    "    return all_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 76\n",
      "Feature extracted for P0  :  711\n",
      "2 / 76\n",
      "Feature extracted for P1  :  711\n",
      "3 / 76\n",
      "Feature extracted for P10  :  711\n",
      "4 / 76\n",
      "Feature extracted for P11  :  711\n",
      "5 / 76\n",
      "Feature extracted for P12  :  711\n",
      "6 / 76\n",
      "Feature extracted for P13  :  711\n",
      "7 / 76\n",
      "Feature extracted for P14  :  711\n",
      "8 / 76\n",
      "Feature extracted for P15  :  711\n",
      "9 / 76\n",
      "Feature extracted for P16  :  711\n",
      "10 / 76\n",
      "Feature extracted for P17  :  711\n",
      "11 / 76\n",
      "Feature extracted for P18  :  711\n",
      "12 / 76\n",
      "Feature extracted for P19  :  711\n",
      "13 / 76\n",
      "Feature extracted for P2  :  711\n",
      "14 / 76\n",
      "Feature extracted for P20  :  711\n",
      "15 / 76\n",
      "Feature extracted for P21  :  711\n",
      "16 / 76\n",
      "Feature extracted for P22  :  711\n",
      "17 / 76\n",
      "Feature extracted for P23  :  711\n",
      "18 / 76\n",
      "Feature extracted for P24  :  711\n",
      "19 / 76\n",
      "Feature extracted for P25  :  711\n",
      "20 / 76\n",
      "Feature extracted for P26  :  711\n",
      "21 / 76\n",
      "Feature extracted for P27  :  711\n",
      "22 / 76\n",
      "Feature extracted for P28  :  711\n",
      "23 / 76\n",
      "Feature extracted for P29  :  711\n",
      "24 / 76\n",
      "Feature extracted for P3  :  711\n",
      "25 / 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1188\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extracted for P30  :  711\n",
      "26 / 76\n",
      "Feature extracted for P31  :  711\n",
      "27 / 76\n",
      "Feature extracted for P32  :  711\n",
      "28 / 76\n",
      "Feature extracted for P33  :  711\n",
      "29 / 76\n",
      "Feature extracted for P34  :  711\n",
      "30 / 76\n",
      "Feature extracted for P35  :  711\n",
      "31 / 76\n",
      "Feature extracted for P36  :  711\n",
      "32 / 76\n",
      "Feature extracted for P37  :  711\n",
      "33 / 76\n",
      "Feature extracted for P38  :  711\n",
      "34 / 76\n",
      "Feature extracted for P39  :  711\n",
      "35 / 76\n",
      "Feature extracted for P4  :  711\n",
      "36 / 76\n",
      "Feature extracted for P40  :  711\n",
      "37 / 76\n",
      "Feature extracted for P41  :  711\n",
      "38 / 76\n",
      "Feature extracted for P42  :  711\n",
      "39 / 76\n",
      "Feature extracted for P43  :  711\n",
      "40 / 76\n",
      "Feature extracted for P44  :  711\n",
      "41 / 76\n",
      "Feature extracted for P45  :  711\n",
      "42 / 76\n",
      "Feature extracted for P46  :  711\n",
      "43 / 76\n",
      "Feature extracted for P47  :  711\n",
      "44 / 76\n",
      "Feature extracted for P48  :  711\n",
      "45 / 76\n",
      "Feature extracted for P49  :  711\n",
      "46 / 76\n",
      "Feature extracted for P5  :  711\n",
      "47 / 76\n",
      "Feature extracted for P50  :  711\n",
      "48 / 76\n",
      "Feature extracted for P51  :  711\n",
      "49 / 76\n",
      "Feature extracted for P52  :  711\n",
      "50 / 76\n",
      "Feature extracted for P53  :  711\n",
      "51 / 76\n",
      "Feature extracted for P54  :  711\n",
      "52 / 76\n",
      "Feature extracted for P55  :  711\n",
      "53 / 76\n",
      "Feature extracted for P56  :  711\n",
      "54 / 76\n",
      "Feature extracted for P57  :  711\n",
      "55 / 76\n",
      "Feature extracted for P58  :  711\n",
      "56 / 76\n",
      "Feature extracted for P59  :  711\n",
      "57 / 76\n",
      "Feature extracted for P6  :  711\n",
      "58 / 76\n",
      "Feature extracted for P60  :  711\n",
      "59 / 76\n",
      "Feature extracted for P61  :  711\n",
      "60 / 76\n",
      "Feature extracted for P62  :  711\n",
      "61 / 76\n",
      "Feature extracted for P63  :  711\n",
      "62 / 76\n",
      "Feature extracted for P65  :  711\n",
      "63 / 76\n",
      "Feature extracted for P66  :  711\n",
      "64 / 76\n",
      "Feature extracted for P67  :  711\n",
      "65 / 76\n",
      "Feature extracted for P68  :  711\n",
      "66 / 76\n",
      "Feature extracted for P68  :  711\n",
      "67 / 76\n",
      "Feature extracted for P69  :  711\n",
      "68 / 76\n",
      "Feature extracted for P7  :  711\n",
      "69 / 76\n",
      "Feature extracted for P70  :  711\n",
      "70 / 76\n",
      "Feature extracted for P71  :  711\n",
      "71 / 76\n",
      "Feature extracted for P72  :  711\n",
      "72 / 76\n",
      "Feature extracted for P73  :  711\n",
      "73 / 76\n",
      "Feature extracted for P74  :  711\n",
      "74 / 76\n",
      "Feature extracted for P75  :  711\n",
      "75 / 76\n",
      "Feature extracted for P8  :  711\n",
      "76 / 76\n",
      "Feature extracted for P9  :  711\n",
      "\n",
      "Feature Extraction Done\n"
     ]
    }
   ],
   "source": [
    "# Extracting the features from the audio files in the given directory.\n",
    "generated_features = Audio_Feature_Extractor( directory='../1.Data/2.SpiroMask_Audio_Samples/',\n",
    "                                        build_header=False,\n",
    "                                        Apply_Bandpass_Filter=True,cutoff_low=3000,cutoff_high=5000,order=5,\n",
    "                                        Apply_clipping=True,Auto_Clipping=True,\n",
    "                                        Normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the extracted features :  (76, 711)\n"
     ]
    }
   ],
   "source": [
    "np_features = np.array(generated_features)\n",
    "print(\"Shape of the extracted features : \",np_features.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Features and Labels (Ground Truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 713)\n",
      "Feature Set Saved\n"
     ]
    }
   ],
   "source": [
    "Name = \"Autoclip_3000_5000_N95_FEATURES\"    # Name of the file to be saved\n",
    "\n",
    "GT = pd.read_csv('../1.Data/1.Ground_Truth/GroundTruth_Dataset.csv',delimiter=',',dtype='str',index_col=0).reset_index(drop=True)\n",
    "feature_set = pd.DataFrame(generated_features)\n",
    "\n",
    "final = pd.merge(feature_set,GT.iloc[:,[0,3,4,]],left_on=0,right_on='UID').drop(columns=['UID'])\n",
    "Dataset = np.array(final)\n",
    "print(Dataset.shape)\n",
    "\n",
    "if not os.path.exists(('./1.Dataset/{}.npy').format(Name)):\n",
    "    np.save(('./1.Dataset/{}.npy').format(Name),Dataset)\n",
    "    print(\"Feature Set Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
